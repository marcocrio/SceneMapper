# SceneMapper

SceneMapper is a toolkit for analyzing video structure using AI-powered shot boundary detection. It helps extract transitions, generate thumbnails, and export timeline references for editing, tagging, or recreating cuts from a reference video.

---

## üîç What It Does

- Detects scene changes and transitions using [TransNetV2](https://github.com/soCzech/TransNetV2)
- Extracts thumbnails around detected transitions
- Generates structured CSV/JSON timeline files
- (Optional) Prepares output for use in editing software (e.g., Resolve, Premiere)

---

## üì¶ Folder Structure

```
SceneMapper/
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îî‚îÄ‚îÄ [video-name]/
‚îÇ       ‚îú‚îÄ‚îÄ input.mov               # Original video file
‚îÇ       ‚îú‚îÄ‚îÄ predictions.txt         # Transition scores
‚îÇ       ‚îú‚îÄ‚îÄ scenes.txt              # Detected scene boundaries
‚îÇ       ‚îú‚îÄ‚îÄ vis.png                 # Visualization of transitions
‚îÇ       ‚îú‚îÄ‚îÄ thumbnails/             # Thumbnails of key transitions
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ frame_0001.jpg
‚îÇ       ‚îÇ   ‚îî‚îÄ‚îÄ frame_0002.jpg
‚îÇ       ‚îî‚îÄ‚îÄ outputs/                # All exported files for Resolve, Premiere, etc.
‚îÇ           ‚îú‚îÄ‚îÄ [video-name]_timeline.csv
‚îÇ           ‚îî‚îÄ‚îÄ [video-name]_timeline.xml
‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îî‚îÄ‚îÄ TransNetV2/
‚îÇ       ‚îú‚îÄ‚îÄ transnetv2.py
‚îÇ       ‚îú‚îÄ‚îÄ transnetv2-weights/
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ saved_model.pb
‚îÇ       ‚îÇ   ‚îî‚îÄ‚îÄ variables/
‚îÇ       ‚îÇ       ‚îú‚îÄ‚îÄ variables.data-00000-of-00001
‚îÇ       ‚îÇ       ‚îî‚îÄ‚îÄ variables.index
‚îÇ       ‚îî‚îÄ‚îÄ LICENSE
‚îú‚îÄ‚îÄ utils/
‚îÇ   ‚îî‚îÄ‚îÄ ffmpeg_tools.py
‚îú‚îÄ‚îÄ extract_transitions.py
‚îú‚îÄ‚îÄ export_timeline.py
‚îú‚îÄ‚îÄ main.py
‚îú‚îÄ‚îÄ requirements.txt
‚îî‚îÄ‚îÄ README.md
```

---

## üöÄ Quickstart

### 1. Clone the repo

```bash
git clone https://github.com/yourusername/SceneMapper.git
cd SceneMapper
```

### 2. Create and activate a Conda environment

```bash
conda create -n SceneMapper python=3.10
conda activate SceneMapper
```

> ‚ö†Ô∏è **Note**: This assumes a macOS development environment with Apple Silicon chips.

### 3. Install dependencies

```bash
pip install -r requirements.txt
```

### 4. Place your video

Place your video file in:

```
data/[video-name]/input.mov
```

### 5. Run analysis

```bash
python main.py --video data/[video-name]/input.mov
```

This will:
- Run scene detection
- Generate thumbnails
- Output a structured timeline CSV in `outputs/`

---

### üîÑ Updating the TransNetV2 model (weights or code)

To update the model or pull latest changes from upstream:

```bash
cd models/TransNetV2
git pull origin master
```

> This works if the folder was initialized with Git sparse-checkout.  
> If not, follow the setup steps from `scripts/setup_transnetv2.sh` (coming soon).

---

### üîö To deactivate the environment

```bash
conda deactivate
```

---

## üìö Dependencies

- Python 3.8+
- TensorFlow (macOS or CPU-only)
- NumPy
- OpenCV
- Pillow
- ffmpeg (installed via `brew`, `apt`, or `choco`)
- ffmpeg-python

> ‚ö†Ô∏è **Note:** You must have `ffmpeg` installed and accessible via terminal.

---

## üõ†Ô∏è Credits

- Built using [TransNetV2](https://github.com/soCzech/TransNetV2) by Pavel Sofranko, used under the Apache 2.0 License.
- The model and weights are located in `models/TransNetV2/`.
- Additional tooling and automation by [marcocrio](https://github.com/marcocrio).

---

## üß™ TODO

- [ ] Add Instructions for other OS.
- [ ] Add GUI or CLI prompts
- [ ] Support EDL/FCPXML export
- [ ] Add AI captioning for scenes
- [ ] Batch processing of multiple videos
- [ ] Test full pipeline on Linux and Windows







